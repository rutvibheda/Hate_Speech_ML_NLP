{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, cohen_kappa_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "scaler = StandardScaler()\n",
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>scale</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>binary</th>\n",
       "      <th>QuestionMarkCount</th>\n",
       "      <th>QuotationMarkCount</th>\n",
       "      <th>ExclamationMarkCount</th>\n",
       "      <th>AllCapitalised</th>\n",
       "      <th>bitch</th>\n",
       "      <th>...</th>\n",
       "      <th>#sex</th>\n",
       "      <th>#xxx</th>\n",
       "      <th>blow</th>\n",
       "      <th>mother</th>\n",
       "      <th>drug</th>\n",
       "      <th>rap</th>\n",
       "      <th>sexi</th>\n",
       "      <th>lip</th>\n",
       "      <th>thick</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  scale  Pos  Neg  binary  QuestionMarkCount  QuotationMarkCount  \\\n",
       "0      2     -1    1   -2      -1                  0                   1   \n",
       "1      1     -2    1   -3      -1                  0                   0   \n",
       "2      1     -2    2   -4      -1                  1                   0   \n",
       "3      1      1    2   -1       1                  0                   0   \n",
       "4      1      0    2   -2       1                  0                   0   \n",
       "\n",
       "   ExclamationMarkCount  AllCapitalised  bitch  ...  #sex  #xxx  blow  mother  \\\n",
       "0                     0               0      0  ...     0     0     0       0   \n",
       "1                     2               0      0  ...     0     0     0       0   \n",
       "2                     0               0      1  ...     0     0     0       0   \n",
       "3                     0               0      0  ...     0     0     0       0   \n",
       "4                     0               0      1  ...     0     0     0       0   \n",
       "\n",
       "   drug  rap  sexi  lip  thick  count  \n",
       "0     0    0     0    0      0      1  \n",
       "1     0    0     0    0      0      2  \n",
       "2     0    0     0    0      0      4  \n",
       "3     0    0     0    0      0      1  \n",
       "4     0    0     0    0      0      2  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('final_dataset.csv',index_col=0)\n",
    "data2 = pd.read_csv('final_dataset2.csv',index_col=0)\n",
    "data['count'] = data2['count']\n",
    "# data['class'] = data['class'].replace([0],1)\n",
    "# df1= data.groupby('class')['class'].count()\n",
    "# print(df1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data.iloc[:,1:]  #independent columns\n",
    "X = minmax.fit_transform(X)\n",
    "y = data.iloc[:,0]    #target column i.e price range\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.83260496e-02 1.47926809e-02 3.02119750e-02 1.32783950e-02\n",
      " 1.48704589e-02 2.96240903e-02 1.54075163e-02 2.76126757e-02\n",
      " 1.66316833e-01 2.18924075e-02 1.76592674e-02 1.49788578e-02\n",
      " 1.60594101e-02 1.43157862e-02 9.98240460e-03 4.25261150e-02\n",
      " 1.32221512e-02 1.19708835e-01 2.88944321e-03 9.39678584e-03\n",
      " 1.52577185e-02 6.43889669e-02 3.81498632e-03 3.29525732e-03\n",
      " 2.67196972e-03 4.19200540e-03 2.08078937e-03 3.07093385e-03\n",
      " 5.57931026e-03 3.29445697e-03 2.75093937e-03 1.89998878e-03\n",
      " 7.89153086e-03 4.06895757e-03 2.92295402e-03 3.76432877e-03\n",
      " 7.50482013e-03 2.04858512e-03 2.08926641e-03 1.45879801e-02\n",
      " 1.36244436e-03 9.90599348e-03 2.95852992e-03 2.40302075e-03\n",
      " 1.92282605e-03 2.53196818e-03 6.25973786e-03 2.74013278e-03\n",
      " 1.77152047e-03 2.12339507e-03 1.80389161e-03 1.88614665e-03\n",
      " 1.42949996e-03 4.27584288e-03 2.49658198e-03 1.28494503e-03\n",
      " 1.39995008e-03 2.80418947e-03 1.54060711e-03 1.77352037e-03\n",
      " 1.78436451e-03 1.55545040e-03 6.90363176e-04 1.06250123e-03\n",
      " 9.73036007e-04 1.35571981e-03 1.72449390e-03 9.31796942e-04\n",
      " 3.10979736e-03 1.12004946e-03 1.02958346e-03 4.07305898e-04\n",
      " 1.06546150e-03 1.04125090e-03 8.32638069e-04 1.34754959e-03\n",
      " 9.66048504e-04 4.56346779e-04 5.42907256e-03 9.25153731e-04\n",
      " 1.19604988e-03 1.16131274e-03 6.69451384e-04 8.70167322e-04\n",
      " 9.81022511e-04 7.69344366e-04 8.62312814e-04 9.49532952e-04\n",
      " 1.21665045e-03 7.55639461e-04 1.58964049e-03 9.79558431e-04\n",
      " 1.28320739e-03 9.25019599e-04 4.34399851e-04 5.44203007e-04\n",
      " 1.11525774e-03 4.39433969e-04 9.11253450e-04 9.71297626e-04\n",
      " 1.73294720e-03 9.27786098e-04 7.05910303e-04 7.47591995e-04\n",
      " 8.85470791e-04 6.33123357e-04 1.13252095e-03 7.80577439e-04\n",
      " 1.23096057e-03 3.80376830e-04 8.75452245e-04 9.15318463e-04\n",
      " 8.82583294e-04 6.74718421e-04 6.07548867e-04 2.94219602e-03\n",
      " 2.14229530e-04 7.47290242e-04 0.00000000e+00 1.30772835e-03\n",
      " 7.24848527e-04 6.89809123e-04 1.17040615e-03 4.26128654e-04\n",
      " 1.01289441e-04 3.87734282e-04 3.30477256e-04 7.25572947e-04\n",
      " 8.00721233e-04 4.52574369e-04 3.11371475e-03 7.23132971e-04\n",
      " 2.11523628e-04 1.97741988e-04 1.08024335e-03 2.64797610e-06\n",
      " 1.47998424e-04 1.63642861e-04 4.66607315e-04 5.50012436e-04\n",
      " 7.36957210e-04 2.92425466e-04 2.88135059e-04 2.34361920e-04\n",
      " 1.25638679e-04 9.61759553e-02]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=data.columns[1:])\n",
    "feat_importances.nlargest(30).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bitch', 'hoe', 'count', 'pussi', 'trash', 'Neg', 'QuotationMarkCount',\n",
      "       'AllCapitalised', 'faggot', 'scale'],\n",
      "      dtype='object')\n",
      "['bitch', 'hoe', 'count', 'pussi', 'trash', 'Neg', 'QuotationMarkCount', 'AllCapitalised', 'faggot', 'scale', 'fuck', 'nigger', 'ExclamationMarkCount', 'shit', 'nigga', 'QuestionMarkCount', 'Pos', 'niggah', 'ass', 'binary', 'fag', 'white', 'nicca', 'retard', 'cunt', 'nig', 'monkey', 'dyke', 'nigguh', 'ghetto', 'queer', 'fuckin', 'call', 'cracker', 'black', 'coon', 'twat', 'negro', 'gay', 'dick', 'red', 'tri', 'hate', 'teabagg', 'racist', 'redneck', 'kill', 'mean', 'bad', 'work', 'die', 'spic', 'stupid', 'smh', 'beaner', 'ugli', 'whitey', 'jew', 'wetback', 'race', 'suck', 'tranni', 'hit', 'hell', 'beat', 'head', 'dumb', 'babi', 'fat', 'mad', 'pick', 'money', 'stfu', 'chick', 'leav', 'gook', 'mom', 'parti', 'sinc', 'throw', 'shoot', 'high', 'sex', 'bruh', 'cri', 'sorri', 'fight', 'hood', 'bag', '_jason', 'pig', 'asshol', 'muzzi', 'whore', 'cut', 'sick', 'pop', 'polic', 'swear', 'thug', 'omg', 'piss', 'problem', 'muslim', 'tcot', 'slut', 'shot', 'broke', 'drop', 'steal', 'darki', 'drug', 'thot', 'wtf', 'nude', 'throat', 'lame', 'tf', 'ju', 'mexican', 'niggaz', 'understand', 'mother', '_afc', 'blow', 'rape', 'mf', 'punk', 'homo', 'weed', 'cop', 'booti', 'nasti', 'porn', 'rap', 'sexi', 'lip', 'israel', 'skinni', 'kno', '#xxx', '#sex', 'thick', 'slap', 'xxx', 'Ã°Å¸â€˜Å ']\n"
     ]
    }
   ],
   "source": [
    "print(feat_importances.nlargest(10).index)\n",
    "columns = list(feat_importances.nlargest(150).index)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['bitch','hoe','pussi','trash','QuotationMarkCount','AllCapitalised','faggot','fuck','scale','nigger','niggah','shit','nigga','ass',\n",
    "#            'ExclamationMarkCount','QuestionMarkCount','nicca','Neg','Pos','retard','binary','fag','white','cunt','nig','dyke','monkey','queer','fuckin','nigguh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bitch</th>\n",
       "      <th>hoe</th>\n",
       "      <th>count</th>\n",
       "      <th>pussi</th>\n",
       "      <th>trash</th>\n",
       "      <th>Neg</th>\n",
       "      <th>QuotationMarkCount</th>\n",
       "      <th>AllCapitalised</th>\n",
       "      <th>faggot</th>\n",
       "      <th>scale</th>\n",
       "      <th>...</th>\n",
       "      <th>lip</th>\n",
       "      <th>israel</th>\n",
       "      <th>skinni</th>\n",
       "      <th>kno</th>\n",
       "      <th>#xxx</th>\n",
       "      <th>#sex</th>\n",
       "      <th>thick</th>\n",
       "      <th>slap</th>\n",
       "      <th>xxx</th>\n",
       "      <th>Ã°Å¸â€˜Å </th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bitch  hoe  count  pussi  trash  Neg  QuotationMarkCount  AllCapitalised  \\\n",
       "0      0    0      1      0      1   -2                   1               0   \n",
       "1      0    1      2      0      0   -3                   0               0   \n",
       "2      1    0      4      0      0   -4                   0               0   \n",
       "3      0    0      1      0      0   -1                   0               0   \n",
       "4      1    0      2      0      0   -2                   0               0   \n",
       "\n",
       "   faggot  scale  ...  lip  israel  skinni  kno  #xxx  #sex  thick  slap  xxx  \\\n",
       "0       0     -1  ...    0       0       0    0     0     0      0     0    0   \n",
       "1       0     -2  ...    0       0       0    0     0     0      0     0    0   \n",
       "2       0     -2  ...    0       0       0    0     0     0      0     0    0   \n",
       "3       0      1  ...    0       0       0    0     0     0      0     0    0   \n",
       "4       0      0  ...    0       0       0    0     0     0      0     0    0   \n",
       "\n",
       "   Ã°Å¸â€˜Å   \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = data[columns]\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new[columns].to_numpy()\n",
    "X = minmax.fit_transform(X)\n",
    "y = data['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,stratify=data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAccuracy(X_train,y_train,X_test,y_test):\n",
    "    lr=LogisticRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred=lr.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('Logistic Accuracy: ', accuracy_score(y_test, y_pred) * 100)\n",
    "#     return accuracy_score(y_test, y_pred) * 100\n",
    "    \n",
    "    \n",
    "    clf = RandomForestClassifier(max_depth=35,random_state=0, min_samples_leaf=1, bootstrap=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    Score = clf.score(X_test,y_test)\n",
    "#     return Score*100\n",
    "    print('Random Forest: ',Score*100)\n",
    "    \n",
    "    classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "#     NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "    log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "    log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        name = clf.__class__.__name__\n",
    "\n",
    "        print(\"=\"*30)\n",
    "        print(name)\n",
    "\n",
    "        print('****Results****')\n",
    "        train_predictions = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, train_predictions)\n",
    "        print(\"Accuracy: {:.4%}\".format(acc))\n",
    "\n",
    "        train_predictions = clf.predict_proba(X_test)\n",
    "        ll = log_loss(y_test, train_predictions)\n",
    "        print(\"Log Loss: {}\".format(ll))\n",
    "\n",
    "        log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "        log = log.append(log_entry)\n",
    "\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  56  198   32]\n",
      " [  35 3630  173]\n",
      " [   1   39  793]]\n",
      "Logistic Accuracy:  90.35707080895703\n",
      "Random Forest:  89.02562033487996\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 86.8872%\n",
      "Log Loss: 3.1601285292399286\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 89.2274%\n",
      "Log Loss: 0.5479381526337334\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 88.5616%\n",
      "Log Loss: 1.0102678713204178\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 88.6423%\n",
      "Log Loss: 0.2995398399001043\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 26.1045%\n",
      "Log Loss: 24.156403848934517\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 87.8354%\n",
      "Log Loss: 0.4556929757854189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 22.9574%\n",
      "Log Loss: 26.567809072275686\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "checkAccuracy(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = data.corr()\n",
    "top_corr_features = corrmat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['class', 'scale', 'Pos', 'Neg', 'binary', 'QuestionMarkCount',\n",
      "       'QuotationMarkCount', 'ExclamationMarkCount', 'AllCapitalised', 'bitch',\n",
      "       ...\n",
      "       '#sex', '#xxx', 'blow', 'mother', 'drug', 'rap', 'sexi', 'lip', 'thick',\n",
      "       'count'],\n",
      "      dtype='object', length=147)\n"
     ]
    }
   ],
   "source": [
    "print(top_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(count):\n",
    "    X = data.iloc[:,1:]  #independent columns\n",
    "    X = minmax.fit_transform(X)\n",
    "    y = data.iloc[:,0]   \n",
    "    acc= []\n",
    "    columns = list(feat_importances.nlargest(count).index)\n",
    "    new = data[columns]\n",
    "    X = new[columns].values\n",
    "    X = minmax.fit_transform(X)\n",
    "    y = data['class'].values\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,stratify=data['class'])\n",
    "    return checkAccuracy(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  286    0]\n",
      " [   0 3838    0]\n",
      " [   0  833    0]]\n",
      "Logistic Accuracy:  77.42586241678434\n",
      "Random Forest:  77.42586241678434\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.5388800563042393\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.538838150375121\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 1.0610522741598403\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.5388343733221627\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 59.7135%\n",
      "Log Loss: 0.9383191326700593\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.5495073330058986\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 59.7135%\n",
      "Log Loss: 0.9382777943463022\n",
      "==============================\n",
      "[[   0  286    0]\n",
      " [   0 3838    0]\n",
      " [   0  833    0]]\n",
      "Logistic Accuracy:  77.42586241678434\n",
      "Random Forest:  77.42586241678434\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.47317418782293014\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.4731257027402252\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 1.0568246074321188\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.47316949168439343\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 73.4517%\n",
      "Log Loss: 0.9841443161428486\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.4823189604431687\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 73.4517%\n",
      "Log Loss: 1.0594229096921217\n",
      "==============================\n",
      "[[   2  269   15]\n",
      " [   1 3773   64]\n",
      " [   0  379  454]]\n",
      "Logistic Accuracy:  85.31369780108938\n",
      "Random Forest:  85.31369780108938\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 85.2935%\n",
      "Log Loss: 0.4115703485984334\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 85.2935%\n",
      "Log Loss: 0.398249333509136\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 85.2330%\n",
      "Log Loss: 1.050031929293798\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 85.2935%\n",
      "Log Loss: 0.39253512331503987\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 75.8927%\n",
      "Log Loss: 0.8751979585867099\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 81.0167%\n",
      "Log Loss: 0.42147294281902836\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 75.1463%\n",
      "Log Loss: 0.928287004847738\n",
      "==============================\n",
      "[[   6  189   91]\n",
      " [   5 3465  368]\n",
      " [   0  114  719]]\n",
      "Logistic Accuracy:  84.52693161186201\n",
      "Random Forest:  84.20415573935848\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 84.1840%\n",
      "Log Loss: 0.3936132242384596\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 84.2042%\n",
      "Log Loss: 0.38834084480478787\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 84.0226%\n",
      "Log Loss: 1.0461598495169633\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 84.2042%\n",
      "Log Loss: 0.36994936611026075\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 80.6133%\n",
      "Log Loss: 1.1088932738606347\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 81.0369%\n",
      "Log Loss: 0.3995120594464044\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 79.9475%\n",
      "Log Loss: 1.2239740520417068\n",
      "==============================\n",
      "[[   5  184   97]\n",
      " [   6 3431  401]\n",
      " [   1   74  758]]\n",
      "Logistic Accuracy:  84.6076255799879\n",
      "Random Forest:  86.56445430704055\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 86.5039%\n",
      "Log Loss: 0.3999685037348257\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.5645%\n",
      "Log Loss: 0.36636987000234633\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.5443%\n",
      "Log Loss: 1.0466601237564939\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.6048%\n",
      "Log Loss: 0.3474216715042641\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 80.3107%\n",
      "Log Loss: 1.1750142677418773\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 83.2560%\n",
      "Log Loss: 0.3944093021501256\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.1089%\n",
      "Log Loss: 1.2472023513997197\n",
      "==============================\n",
      "[[   4  215   67]\n",
      " [   9 3595  234]\n",
      " [   1  163  669]]\n",
      "Logistic Accuracy:  86.10046399031673\n",
      "Random Forest:  86.44341335485173\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4434%\n",
      "Log Loss: 0.4942231646179135\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4434%\n",
      "Log Loss: 0.40950671287748047\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4434%\n",
      "Log Loss: 1.0447370032883652\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4434%\n",
      "Log Loss: 0.34522899076348557\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 81.2790%\n",
      "Log Loss: 1.278034401771164\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 83.9016%\n",
      "Log Loss: 0.39301969274657794\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.8957%\n",
      "Log Loss: 1.3515788228643333\n",
      "==============================\n",
      "[[   6  219   61]\n",
      " [   5 3566  267]\n",
      " [   2  142  689]]\n",
      "Logistic Accuracy:  85.95924954609643\n",
      "Random Forest:  86.34254589469437\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 86.1812%\n",
      "Log Loss: 0.6931216375860806\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.3425%\n",
      "Log Loss: 0.5508031573231815\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4434%\n",
      "Log Loss: 1.0438844370338127\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.5443%\n",
      "Log Loss: 0.35540940585046127\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 80.6334%\n",
      "Log Loss: 1.2340383886366257\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 83.0139%\n",
      "Log Loss: 0.4066894634023187\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.0484%\n",
      "Log Loss: 1.326994044045671\n",
      "==============================\n",
      "[[   2  216   68]\n",
      " [   1 3585  252]\n",
      " [   0  149  684]]\n",
      "Logistic Accuracy:  86.16098446641114\n",
      "Random Forest:  86.6653217671979\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 86.2820%\n",
      "Log Loss: 0.9694040204608322\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.6048%\n",
      "Log Loss: 0.5746181037844087\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.8469%\n",
      "Log Loss: 1.0471577073462013\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.7460%\n",
      "Log Loss: 0.3509850532712497\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 81.5211%\n",
      "Log Loss: 1.2217449414162125\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 83.8007%\n",
      "Log Loss: 0.40325406249110696\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.4317%\n",
      "Log Loss: 1.3020462289626422\n",
      "==============================\n",
      "[[  17  203   66]\n",
      " [  20 3536  282]\n",
      " [   0  137  696]]\n",
      "Logistic Accuracy:  85.71716764171879\n",
      "Random Forest:  86.14081097437966\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 85.7777%\n",
      "Log Loss: 1.130729066369678\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.1408%\n",
      "Log Loss: 0.5656409359464063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.3224%\n",
      "Log Loss: 1.0457718323420413\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.9881%\n",
      "Log Loss: 0.3379387069390966\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 81.8237%\n",
      "Log Loss: 1.7260723744930024\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 84.1638%\n",
      "Log Loss: 0.42053300884219275\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 81.5816%\n",
      "Log Loss: 1.8023837292509424\n",
      "==============================\n",
      "[[  23  204   59]\n",
      " [  21 3572  245]\n",
      " [   1  163  669]]\n",
      "Logistic Accuracy:  86.01977002219084\n",
      "Random Forest:  86.24167843453702\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 85.6163%\n",
      "Log Loss: 1.6641519387005037\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.3425%\n",
      "Log Loss: 0.6782090413537547\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.9679%\n",
      "Log Loss: 1.0423165522141995\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 87.1293%\n",
      "Log Loss: 0.3282704630456469\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 81.8035%\n",
      "Log Loss: 2.6217115644863185\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 85.1120%\n",
      "Log Loss: 0.40773043466843156\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 16.8045%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:718: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:718: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8787b46560dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-478d691aa496>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(count)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheckAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-cad5d0466c9b>\u001b[0m in \u001b[0;36mcheckAccuracy\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Log Loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnatural\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m     \"\"\"\n\u001b[0;32m-> 2241\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2242\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "acc= []\n",
    "for i in range(1,150):\n",
    "    acc.append(train(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(acc.index(max(acc)))\n",
    "print(max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  286    0]\n",
      " [   0 3838    0]\n",
      " [   0  833    0]]\n",
      "Logistic Accuracy:  77.42586241678434\n",
      "Random Forest:  77.42586241678434\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.5378544507266689\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.5378541231177097\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 1.0627890621428326\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.5378796824302208\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 59.2294%\n",
      "Log Loss: 0.8481865014542246\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.5506673583153882\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 59.2294%\n",
      "Log Loss: 0.8481462072676329\n",
      "==============================\n",
      "[[   0  286    0]\n",
      " [   0 3838    0]\n",
      " [   0  833    0]]\n",
      "Logistic Accuracy:  77.42586241678434\n",
      "Random Forest:  77.42586241678434\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.47499033169728944\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.4750001908976427\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 1.0582661884861513\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.4750189542407692\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 72.7456%\n",
      "Log Loss: 0.9517353731652837\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 77.4259%\n",
      "Log Loss: 0.4862298823016749\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 72.7456%\n",
      "Log Loss: 1.0304499496775763\n",
      "==============================\n",
      "[[   2  273   11]\n",
      " [   1 3765   72]\n",
      " [   1  384  448]]\n",
      "Logistic Accuracy:  85.03126891264878\n",
      "Random Forest:  85.03126891264878\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 85.0313%\n",
      "Log Loss: 0.42039029499619474\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 85.0313%\n",
      "Log Loss: 0.4140114993726275\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 84.9707%\n",
      "Log Loss: 1.0474060941618721\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 85.0514%\n",
      "Log Loss: 0.3898202863578548\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 76.9215%\n",
      "Log Loss: 0.8380852132642251\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 81.6219%\n",
      "Log Loss: 0.4154567222232385\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 75.7918%\n",
      "Log Loss: 0.882260506103899\n",
      "==============================\n",
      "[[   4  186   96]\n",
      " [   6 3462  370]\n",
      " [   0  108  725]]\n",
      "Logistic Accuracy:  84.54710510389349\n",
      "Random Forest:  85.05144240468026\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 84.9707%\n",
      "Log Loss: 0.3637111265470809\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 85.0313%\n",
      "Log Loss: 0.363802320897035\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 85.0313%\n",
      "Log Loss: 1.047407417251163\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 85.0313%\n",
      "Log Loss: 0.3580504335220009\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 80.7747%\n",
      "Log Loss: 0.9980308755719768\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 81.2387%\n",
      "Log Loss: 0.3926928233117649\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.4721%\n",
      "Log Loss: 1.1058627013720286\n",
      "==============================\n",
      "[[   4  176  106]\n",
      " [   1 3406  431]\n",
      " [   0   86  747]]\n",
      "Logistic Accuracy:  83.86120637482348\n",
      "Random Forest:  85.91890256203348\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 85.9189%\n",
      "Log Loss: 0.395727261511854\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 85.9189%\n",
      "Log Loss: 0.3702345899107507\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 85.9996%\n",
      "Log Loss: 1.047374347786351\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 85.9189%\n",
      "Log Loss: 0.35665971852267786\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 80.7141%\n",
      "Log Loss: 1.2123247156598138\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 82.8929%\n",
      "Log Loss: 0.39374334375354836\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.4519%\n",
      "Log Loss: 1.2786113171539444\n",
      "==============================\n",
      "[[   9  222   55]\n",
      " [   6 3596  236]\n",
      " [   0  165  668]]\n",
      "Logistic Accuracy:  86.20133145047407\n",
      "Random Forest:  86.5241073229776\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4232%\n",
      "Log Loss: 0.41105362314265864\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.5241%\n",
      "Log Loss: 0.3772051220048382\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4434%\n",
      "Log Loss: 1.0469875320541118\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4636%\n",
      "Log Loss: 0.34488692389097425\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 80.8957%\n",
      "Log Loss: 1.1860005741877795\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 83.5788%\n",
      "Log Loss: 0.38783924167553463\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.5326%\n",
      "Log Loss: 1.2648588531254297\n",
      "==============================\n",
      "[[   8  215   63]\n",
      " [   9 3608  221]\n",
      " [   0  175  658]]\n",
      "Logistic Accuracy:  86.22150494250555\n",
      "Random Forest:  86.6048012911035\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 86.5039%\n",
      "Log Loss: 0.6226684848154354\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 86.6250%\n",
      "Log Loss: 0.4359537596978862\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.5039%\n",
      "Log Loss: 1.0464926881276293\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.6653%\n",
      "Log Loss: 0.3477037469257979\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 81.7632%\n",
      "Log Loss: 1.073367968201204\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 83.9419%\n",
      "Log Loss: 0.3832583969948003\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 81.0974%\n",
      "Log Loss: 1.1490834100009135\n",
      "==============================\n",
      "[[   6  213   67]\n",
      " [   8 3557  273]\n",
      " [   0  157  676]]\n",
      "Logistic Accuracy:  85.51543272140407\n",
      "Random Forest:  85.89872907000202\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 85.6768%\n",
      "Log Loss: 0.9479378275527667\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 85.9391%\n",
      "Log Loss: 0.5382993650089939\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 86.2215%\n",
      "Log Loss: 1.0472404916508131\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 86.4636%\n",
      "Log Loss: 0.351660204354853\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 80.8755%\n",
      "Log Loss: 1.2194045717532576\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 82.5903%\n",
      "Log Loss: 0.40529066602910174\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 80.0686%\n",
      "Log Loss: 1.3063590113705792\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  22  193   71]\n",
      " [  27 3556  255]\n",
      " [   1  159  673]]\n",
      "Logistic Accuracy:  85.75751462578172\n",
      "Random Forest:  85.91890256203348\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 85.2532%\n",
      "Log Loss: 1.3122050180332276\n"
     ]
    }
   ],
   "source": [
    "acc= []\n",
    "for i in range(1,150):\n",
    "    acc.append(train(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc.index(max(acc)))\n",
    "print(max(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
