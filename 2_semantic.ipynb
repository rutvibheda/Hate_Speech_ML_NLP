{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>['woman', 'complain', 'cleaning', 'house', 'ma...</td>\n",
       "      <td>['woman', 'complain', 'clean', 'hous', 'man', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>['boy', 'dats', 'cold', '...', 'tyga', 'dwn', ...</td>\n",
       "      <td>['boy', 'dat', 'cold', '...', 'tyga', 'dwn', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...</td>\n",
       "      <td>['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>['_g_anderson', '_based', 'look', 'like', 'tra...</td>\n",
       "      <td>['_g_anderson', '_base', 'look', 'like', 'tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>['shit', 'hear', 'might', 'true', 'might', 'fa...</td>\n",
       "      <td>['shit', 'hear', 'might', 'true', 'might', 'fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet  \\\n",
       "0      1  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      0  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      0  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      0  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      0  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  ['woman', 'complain', 'cleaning', 'house', 'ma...   \n",
       "1  ['boy', 'dats', 'cold', '...', 'tyga', 'dwn', ...   \n",
       "2  ['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...   \n",
       "3  ['_g_anderson', '_based', 'look', 'like', 'tra...   \n",
       "4  ['shit', 'hear', 'might', 'true', 'might', 'fa...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  ['woman', 'complain', 'clean', 'hous', 'man', ...  \n",
       "1  ['boy', 'dat', 'cold', '...', 'tyga', 'dwn', '...  \n",
       "2  ['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...  \n",
       "3  ['_g_anderson', '_base', 'look', 'like', 'tran...  \n",
       "4  ['shit', 'hear', 'might', 'true', 'might', 'fa...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df= pd.read_csv(\"Stemmed_Data2.csv\")\n",
    "orig_df.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "# print(orig_df.columns)\n",
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40290, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>['woman', 'complain', 'cleaning', 'house', 'ma...</td>\n",
       "      <td>['woman', 'complain', 'clean', 'hous', 'man', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>['boy', 'dats', 'cold', '...', 'tyga', 'dwn', ...</td>\n",
       "      <td>['boy', 'dat', 'cold', '...', 'tyga', 'dwn', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...</td>\n",
       "      <td>['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>['_g_anderson', '_based', 'look', 'like', 'tra...</td>\n",
       "      <td>['_g_anderson', '_base', 'look', 'like', 'tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>['shit', 'hear', 'might', 'true', 'might', 'fa...</td>\n",
       "      <td>['shit', 'hear', 'might', 'true', 'might', 'fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  class                                              tweet  \\\n",
       "0           0      1  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1           1      0  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2           2      0  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3           3      0  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4           4      0  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  ['woman', 'complain', 'cleaning', 'house', 'ma...   \n",
       "1  ['boy', 'dats', 'cold', '...', 'tyga', 'dwn', ...   \n",
       "2  ['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...   \n",
       "3  ['_g_anderson', '_based', 'look', 'like', 'tra...   \n",
       "4  ['shit', 'hear', 'might', 'true', 'might', 'fa...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  ['woman', 'complain', 'clean', 'hous', 'man', ...  \n",
       "1  ['boy', 'dat', 'cold', '...', 'tyga', 'dwn', '...  \n",
       "2  ['dawg', 'ever', 'fuck', 'bitch', 'start', 'cr...  \n",
       "3  ['_g_anderson', '_base', 'look', 'like', 'tran...  \n",
       "4  ['shit', 'hear', 'might', 'true', 'might', 'fa...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig2= pd.read_csv('Stemmed_Data2.csv')\n",
    "print(orig2.shape)\n",
    "orig2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig2['tweet']=orig2['tweet'].apply(str)\n",
    "# orig_df['tweet']=orig_df['tweet'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTags(s):\n",
    "    l = [i  for i in s.split() if i.startswith(\"#\") ]\n",
    "    for i in l:\n",
    "        expanded = \" \".join([a for a in re.split('([A-Z][a-z]+)', i[1:]) if a])\n",
    "        s = s.replace(i,expanded)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punctuation_and_allcaps(tweet):\n",
    "    p={'allCaps':0}\n",
    "    if type(tweet)==str:\n",
    "        tweet_str= tweet\n",
    "    else:\n",
    "        tweet_str=' '.join(tweet)\n",
    "    temp= re.findall('[A-Z]{2,}', tweet_str)\n",
    "    p['allCaps']=len(temp)\n",
    "    \n",
    "    for i in tweet:\n",
    "        if i in string.punctuation and i not in ['@','#'] and i not in p:\n",
    "            p[i]=tweet.count(i)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "#     tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "#     tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "#     tweet= re.sub('[!*(RT)]','',tweet)\n",
    "    tweet= re.sub(\"!*\\sRT?\", ' ', tweet)\n",
    "    tweet= re.sub(\"\\A!*\", '',  tweet)\n",
    "    tweet= re.sub(\"\\A\\sRT\\s\", ' ',  tweet)\n",
    "    \n",
    "    \n",
    "    tweet = re.sub(r'RT', '', tweet)\n",
    "    tweet = re.sub(r'@[A-Za-z0-9]+', '', tweet)\n",
    "    x= count_punctuation_and_allcaps(tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = splitTags(tweet)\n",
    "#     print(tweet)\n",
    "    # remove hashtags\n",
    "#     # only removing the hash # sign from the word\n",
    "#     tweet = re.sub(r'#', '', tweet)\n",
    "#     tokenize tweets\n",
    "    \n",
    "# %%%%%%% changed preserve case parameter to True\n",
    "    tokenizer = TweetTokenizer(preserve_case=True, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    \n",
    "#     print(x)\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and word not in string.punctuation):  # remove punctuation\n",
    "            tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "#             tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPreprocessingCoulmns(df):\n",
    "    Cols= df.shape[0]\n",
    "    df['QuestionMarkCount']=[None]* Cols\n",
    "    df['QuotationMarkCount']=[None]* Cols\n",
    "    df['ExclamationMarkCount']=[None]* Cols\n",
    "    df['AllCapitalised']=[None]* Cols\n",
    "    for i in range(Cols):\n",
    "        preprocess, l= process_tweet(df['tweet'][i])\n",
    "        df['processed_text'][i]= preprocess\n",
    "        df['QuestionMarkCount'][i]= l['?'] if '?' in l else 0\n",
    "        df['QuotationMarkCount'][i]= l['\\''] if '\\'' in l else 0\n",
    "        df['ExclamationMarkCount'][i]=l['!'] if '!' in l else 0\n",
    "        df['AllCapitalised'][i]= l['allCaps'] if l['allCaps'] else 0\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-3e2a2f50e15a>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['processed_text'][i]= preprocess\n",
      "<ipython-input-35-3e2a2f50e15a>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['QuestionMarkCount'][i]= l['?'] if '?' in l else 0\n",
      "<ipython-input-35-3e2a2f50e15a>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['QuotationMarkCount'][i]= l['\\''] if '\\'' in l else 0\n",
      "<ipython-input-35-3e2a2f50e15a>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['ExclamationMarkCount'][i]=l['!'] if '!' in l else 0\n",
      "<ipython-input-35-3e2a2f50e15a>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['AllCapitalised'][i]= l['allCaps'] if l['allCaps'] else 0\n"
     ]
    }
   ],
   "source": [
    "addPreprocessingCoulmns(orig2)\n",
    "orig2.to_csv('stemmed_semantic_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
      "---------------\n",
      "\n",
      "  @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
      "  @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
      "  @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
      "  : The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
      "  : The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
      "['The', 'shit', 'hear', 'might', 'true', 'might', 'faker', 'bitch', 'told', 'ya', '\\ue011']\n",
      "{'allCaps': 0, ':': 1, '&': 1, ';': 1}\n"
     ]
    }
   ],
   "source": [
    "def debug_stepwise_process_tweet(n):\n",
    "    print(orig2['tweet'][n])\n",
    "    print('---------------\\n')\n",
    "    s= re.sub(\"!*\\sRT?\", ' ', orig2['tweet'][n])\n",
    "    print(s)\n",
    "    t= re.sub(\"\\A!*\", '',  s)\n",
    "    print(t)\n",
    "    r=re.sub(\"\\A\\sRT\\s\", ' ',  t)\n",
    "    print(r)\n",
    "    p = re.sub(r'@[A-Za-z0-9]+', '', r)\n",
    "    print(p)\n",
    "    q = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', p)\n",
    "    print(q)\n",
    "    x,y= process_tweet(orig2['tweet'][n])\n",
    "    print(x)\n",
    "    z=count_punctuation_and_allcaps(r)\n",
    "    print(z)\n",
    "    \n",
    "    \n",
    "debug_stepwise_process_tweet(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allCaps': 1, '!': 6}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_punctuation_and_allcaps(\"FEMIN Dharamshi !!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_punctuation_rows(tweet):\n",
    "#     QuestionMarkCount | QuotationMarkCount | ExclamationMarkCount | AllCapitalised\n",
    "    x, p= process_tweet(tweet) # need to use process tweet to remove redundant exclamation and RT string\n",
    "#     print(p)\n",
    "    res=[]\n",
    "    if '?' in p: \n",
    "        res.append(p['?']) \n",
    "    else:\n",
    "        res.append(0)\n",
    "    if '\\'' in p: \n",
    "        res.append(p['\\'']) \n",
    "    else:\n",
    "        res.append(0)\n",
    "    if '!' in p: \n",
    "        res.append(p['!']) \n",
    "    else: \n",
    "        res.append(0)\n",
    "   \n",
    "    res.append(p['allCaps']) \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 7, 2]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_punctuation_rows('She is such a BAD PERSON !!!!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuestionMarkCount | QuotationMarkCount | ExclamationMarkCount | AllCapitalised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
